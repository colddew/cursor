#!/usr/bin/env python3
"""
å®‰å¾½çœç‰©ç†ç»„/æ‹›ç”Ÿå¤§æœ¬ä¸“ç”¨å¤„ç†è„šæœ¬ (åŸºäº StructureV3)
1. è°ƒç”¨ StructureV3 æ¥å£è·å–é˜…è¯»é¡ºåºæ­£ç¡®çš„æ–‡æœ¬
2. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æä¸‰åˆ—æ•°æ® ([ä»£ç ] [åç§°] [äººæ•°/å¤‡æ³¨])
3. å¤„ç†è·¨è¡Œå¤‡æ³¨åŠå¤šè¡Œä¸“ä¸šè¯¦ç»†è¯´æ˜
4. è¿‡æ»¤è¯´æ˜æ€§æ–‡å­—åŠä¼˜åŒ–è¡Œé—´è·
"""

import sys
# ç¦ç”¨ç”Ÿæˆ __pycache__
sys.dont_write_bytecode = True
import os
import re
import time
import argparse
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½é…ç½® (å°½é‡åœ¨å…¶ä»–å¯¼å…¥å‰æ‰§è¡Œ)
load_dotenv()

from openpyxl import Workbook
from openpyxl.styles import Font

# è‡ªåŠ¨å®šä½é¡¹ç›®æ ¹ç›®å½•å¹¶åŠ å…¥ sys.path
script_dir = Path(__file__).resolve().parent
project_root = script_dir.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from scripts.common.baidu_api import call_structure_v3
from scripts.common.baidu_api_ocr import call_paddleocr_vl
from scripts.common.excel_utils import (
    get_header_style, get_common_styles, setup_columns, 
    write_data_row, write_text_row, html_table_to_excel,
    autofit_columns, BeautifulSoup
)
from scripts.common.table_detection import detect_table

class AnhuiProcessor:
    # æ­£åˆ™è§„åˆ™ (å…¼å®¹ StructureV3 çš„ç´§å‡‘æ¨¡å¼ï¼Œç§»é™¤è¡Œé¦–é”šç‚¹ä»¥æ”¯æŒéå¯¹é½æ–‡æœ¬)
    GROUP_PATTERN = re.compile(r"(\d{3,})\s*(.*?)\s*(\d+\s*äºº.*)")
    
    # Codeç»„å˜ä¸ºå¯é€‰ï¼Œåç§°ç»„æ’é™¤æ•°å­—å¼€å¤´
    MAJOR_PATTERN = re.compile(r"([A-Za-z0-9]{2})?\s*([^\d\n\s]{2,}[^\säºº]*)\s*(\d+\s*äºº.*)")
    
    # å¡«æŠ¥è¯´æ˜ç‰¹å¾æ¨¡å¼ (åŸºäºç»“æ„æè¿°ç‰¹å¾)
    INSTRUCTION_FEATURES = [
        r"å‰\s*\d+\s*ä½æ•°å­—ä¸º.*ä»£ç ",
        r"å«\s*\d+\s*ä½ä¸“ä¸šç»„ä»£ç ",
        r"æ‹¬å·å†…ä¸ºä¸“ä¸šæ”¶è´¹æ ‡å‡†",
        r"ä¸“ä¸šåç§°åæ•°å­—ä¸º.*äººæ•°",
        r"é™¢æ ¡åç§°åä¸ºä¸“ä¸šç»„"
    ]

    def __init__(self):
        self.api_url = os.getenv('AISTUDIO_STRUCTURE_URL')
        self.token = os.getenv('AISTUDIO_STRUCTURE_TOKEN') or os.getenv('AISTUDIO_TOKEN')

    def is_instruction_line(self, line):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¡«æŠ¥è¯´æ˜ç±»å‹çš„æ— æ•ˆæ–‡å­—"""
        # ä¼˜å…ˆåˆ¤æ–­ï¼šå¦‚æœæ˜¯æ•°æ®è¡Œï¼ˆä»¥æ•°å­—ä»£ç å¼€å¤´ä¸”åŒ…å«äººæ•°ï¼‰ï¼Œåˆ™ä¸æ˜¯è¯´æ˜æ–‡å­—
        if re.match(r'^\d{2,4}\s+', line) and re.search(r'\d+\s*äºº', line):
            return False
        
        # æ£€æŸ¥ç‰¹å¾æ¨¡å¼
        for feature in self.INSTRUCTION_FEATURES:
            if re.search(feature, line):
                return True
        
        # é¢å¤–ç‰¹å¾è¯æ£€æŸ¥ï¼ˆPage 05 ç‰¹æœ‰çš„è¯´æ˜æ–‡å­—ï¼‰
        instruction_keywords = [
            "è€ƒç”Ÿæœ¬äººåŠ¡å¿…", "å¡«æŠ¥å¿—æ„¿", "å¿—æ„¿ä¿¡æ¯", "å½•å…¥é”™è¯¯",
            "æ‹›ç”Ÿè®¡åˆ’ä¸åˆ†", "ç§‘ç›®ç»„åˆ", "ç»¼åˆåˆ†è®¡ç®—å…¬å¼", "ç»¼åˆåˆ†=",
            "å¹³è¡Œå¿—æ„¿", "é™¢æ ¡ä¸“ä¸šç»„å¿—æ„¿", "ä¸“ä¸šæœä»å¿—æ„¿",
            "$$"  # æ•°å­¦å…¬å¼æ ‡è®°
        ]
        if any(kw in line for kw in instruction_keywords):
            return True
        
        # è¶…é•¿æ®µè½æ£€æŸ¥ï¼šè¶…è¿‡100å­—ç¬¦å¾ˆå¯èƒ½æ˜¯è¯´æ˜æ–‡å­—ï¼ˆä¸å†è¦æ±‚ä¸åŒ…å«"äºº"ï¼‰
        if len(line) > 100:
            return True
        
        return False

    def run(self, image_path, output_dir):
        if not self.api_url or not self.token:
            print("âŒ é”™è¯¯: è¯·åœ¨ .env ä¸­é…ç½® AISTUDIO_STRUCTURE_URL å’Œ AISTUDIO_STRUCTURE_TOKEN")
            return

        print(f"ğŸ” æ­£åœ¨å¤„ç† (Anhui): {Path(image_path).name}")
        
        # 1. OpenCV é¢„æ£€æµ‹ï¼šè¡¨æ ¼è¿˜æ˜¯æ–‡æœ¬ï¼Ÿ
        # æ ¹æ® model_preference å†³å®šæ˜¯å¦å¼ºåˆ¶ä½¿ç”¨æŸä¸ªæ¨¡å‹
        force_mode = getattr(self, 'model_preference', 'auto')
        if force_mode == 'auto':
            force_mode = None  # è‡ªåŠ¨æ£€æµ‹
        
        is_table, intersections = detect_table(image_path, force_mode=force_mode)
        
        if force_mode:
            mode_str = f"å¼ºåˆ¶æ¨¡å¼: {'PaddleOCR' if force_mode == 'ocr' else 'StructureV3'}"
        else:
            mode_str = "è¡¨æ ¼æ¨¡å¼ (PaddleOCR)" if is_table else "æ–‡æœ¬æ¨¡å¼ (StructureV3)"
        print(f"   ğŸ“Š æ£€æµ‹ç»“æœ: äº¤ç‚¹æ•°={intersections} => {mode_str}")
        
        full_text = ""
        
        if is_table:
            # === è¡¨æ ¼æ¨¡å¼ï¼šè°ƒç”¨æ ‡å‡† OCR ===
            ocr_api_url = os.getenv("AISTUDIO_API_URL")
            if not ocr_api_url:
                print("âŒ é”™è¯¯: æœªåœ¨ .env ä¸­é…ç½® AISTUDIO_API_URL (ç”¨äºè¡¨æ ¼æ¨¡å¼)")
                return
             
            response = call_paddleocr_vl(image_path, ocr_api_url, self.token)
            if response.status_code != 200:
                print(f"âŒ OCR API è°ƒç”¨å¤±è´¥: {response.text}")
                return

            res_json = response.json()
            if res_json.get("errorCode", 0) != 0:
                print(f"âŒ OCR ä¸šåŠ¡é”™è¯¯: {res_json.get('errorMsg')}")
                return
            
            layout_results = res_json.get("result", {}).get("layoutParsingResults", [])
            for res in layout_results:
                full_text += res.get("markdown", {}).get("text", "") + "\n"
        else:
            # === æ–‡æœ¬æ¨¡å¼ï¼šè°ƒç”¨ StructureV3 (Low Threshold) ===
            response = call_structure_v3(image_path, self.api_url, self.token)
            if response.status_code != 200:
                print(f"âŒ V3 API è°ƒç”¨å¤±è´¥: {response.text}")
                return

            res_json = response.json()
            if res_json.get("errorCode", 0) != 0:
                print(f"âŒ V3 ä¸šåŠ¡é”™è¯¯: {res_json.get('errorMsg')}")
                return

            layout_results = res_json.get("result", {}).get("layoutParsingResults", [])
            for res in layout_results:
                full_text += res.get("markdown", {}).get("text", "") + "\n"

        # 2. ä¿å­˜ä¸­é—´ç»“æœ
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        base_name = Path(image_path).stem
        md_path = Path(output_dir) / f"{base_name}_{timestamp}.md"
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(full_text)
        print(f"   âœ“ Markdown å·²ä¿å­˜: {md_path}")

        # 3. è§£æä¸º Excel
        wb = self.parse_to_excel(full_text)
        excel_path = Path(output_dir) / f"{base_name}_{timestamp}.xlsx"
        wb.save(excel_path)
        print(f"   âœ“ Excel å·²ä¿å­˜: {excel_path}")

    # å®šä¹‰è¡Œç±»å‹å¸¸é‡
    LINE_TYPE_TITLE = 'TITLE'
    LINE_TYPE_GROUP = 'GROUP'
    LINE_TYPE_MAJOR = 'MAJOR'
    LINE_TYPE_INSTRUCTION = 'INSTRUCTION'
    LINE_TYPE_UNKNOWN = 'UNKNOWN'

    def classify_line(self, line):
        """ç¬¬ä¸€éæ‰«æï¼šç»™æ¯ä¸€è¡Œæ‰“æ ‡ç­¾"""
        line = line.strip()
        if not line: return None, None
        
        # 1. æ ‡é¢˜ - ä¼˜å…ˆæ£€æŸ¥ï¼ˆå¿…é¡»åœ¨è¯´æ˜æ–‡å­—ä¹‹å‰ï¼‰
        # ç‰¹å¾ï¼šä»¥ # å¼€å¤´ï¼ˆMarkdown æ ‡é¢˜ï¼‰ï¼Œæˆ–è€…çŸ­ä¸”åŒ…å«"æ‰¹æ¬¡"å…³é”®è¯
        if line.startswith('#'):
            # å»æ‰ # å·ï¼Œè¿”å›å¹²å‡€çš„æ ‡é¢˜æ–‡æœ¬
            clean_title = line.lstrip('#').strip()
            return self.LINE_TYPE_TITLE, clean_title
        if len(line) < 20 and re.search(r'(æå‰|æœ¬ç§‘|ä¸“ç§‘|é«˜èŒ|è‰ºæœ¯|ä½“è‚²)æ‰¹', line):
            return self.LINE_TYPE_TITLE, line
        
        # 2. æ˜ç¡®çš„è¯´æ˜æ–‡å­—ï¼ˆé•¿æ®µè½è¯´æ˜ï¼‰
        if self.is_instruction_line(line):
            return self.LINE_TYPE_INSTRUCTION, line
            
        # 3. é™¢æ ¡ä¸“ä¸šç»„
        # ç‰¹å¾ï¼šæœ‰3ä½ä»¥ä¸Šæ•°å­—ä»£ç ï¼Œä¸”åŒ…å«"äºº"ï¼ˆStructureV3ç‰¹å¾ï¼‰
        # GROUP_PATTERN: (\d{3,})\s*(.*?)\s*(\d+\s*äºº.*)
        if self.GROUP_PATTERN.search(line):
            # è¯¯åˆ¤é˜²æŠ¤ï¼šå¦‚æœåŒ…å«"å…ƒ/å¹´"ç­‰ä»·æ ¼ç‰¹å¾ï¼Œè¿™å¤šåŠæ˜¯ä¸Šä¸€è¡Œæ–­è¡Œçš„å­¦è´¹ä¿¡æ¯ï¼Œä¸æ˜¯é™¢æ ¡ç»„
            # å…¼å®¹åŠè§’/å’Œå…¨è§’ï¼
            if re.search(r'å…ƒ\s*[\\\/ï¼]\s*å¹´', line):
                return self.LINE_TYPE_UNKNOWN, line
            return self.LINE_TYPE_GROUP, line
            
        # 4. ä¸“ä¸š
        # ç‰¹å¾ï¼šå¯é€‰ä»£ç  + åç§° + äººæ•°
        # MAJOR_PATTERN: ([A-Za-z0-9]{2})?\s*([^\d\n\s]{2,}[^\säºº]*)\s*(\d+\s*äºº.*)
        # å¿…é¡»ä¸¥æ ¼éªŒè¯"äºº"å­—å­˜åœ¨ï¼Œé¿å…è¯¯åˆ¤æ™®é€šæ–‡æœ¬
        if self.MAJOR_PATTERN.search(line):
            # åŒæ ·çš„è¯¯åˆ¤é˜²æŠ¤
            if re.search(r'å…ƒ\s*[\\\/ï¼]\s*å¹´', line):
                return self.LINE_TYPE_UNKNOWN, line
            return self.LINE_TYPE_MAJOR, line
            
        # 5. æœªçŸ¥/å…¶ä»– (å¯èƒ½æ˜¯è¡¨å¤´ä¹±ç ï¼Œä¹Ÿå¯èƒ½æ˜¯è·¨è¡Œå¤‡æ³¨)
        return self.LINE_TYPE_UNKNOWN, line

    def _parse_paddle_format(self, text, wb, ws):
        """è§£æ PaddleOCR çš„ç®€å•æ ¼å¼ï¼ˆæ¯è¡Œç‹¬ç«‹ï¼‰"""
        header_fill, header_font = get_header_style()
        styles = get_common_styles()
        align_center, align_left, border = styles
        
        # === é¢„å¤„ç†ï¼šåˆå¹¶ OCR æ–­è¡Œ + è¿‡æ»¤è¯´æ˜æ–‡å­— ===
        lines = text.split('\n')
        merged_lines = []
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            if not line:
                i += 1
                continue
            
            # ã€æå‰è¿‡æ»¤ã€‘è·³è¿‡è¯´æ˜æ–‡å­—å’Œç‰¹å®šå…³é”®è¯ï¼ˆé¿å…è¿›å…¥merged_linesï¼‰
            if self.is_instruction_line(line):
                i += 1
                continue
            
            if any(kw in line for kw in ["é™¢æ ¡åç§°å‰", "ä¸“ä¸šåç§°å‰", "æ‹›ç”Ÿäººæ•°åæ‹¬å·å†…"]):
                i += 1
                continue
            
            # æ£€æŸ¥åç»­è¡Œæ˜¯å¦éœ€è¦åˆå¹¶ï¼ˆè·³è¿‡ç©ºè¡Œï¼‰
            next_idx = i + 1
            while next_idx < len(lines) and not lines[next_idx].strip():
                next_idx += 1
            
            if next_idx < len(lines):
                next_line = lines[next_idx].strip()
                should_merge = False
                
                # æ¡ä»¶1ï¼šä¸‹ä¸€è¡Œä»¥æ•°å­—+äººå¼€å¤´ï¼Œä¸”å½“å‰è¡Œä¸åŒ…å«"æ•°å­—+äºº"æ¨¡å¼
                if next_line and re.match(r'^\d+\s*äºº', next_line) and not re.search(r'\d+\s*äºº', line):
                    should_merge = True
                
                # æ¡ä»¶2ï¼šä¸‹ä¸€è¡Œä»¥æ‹¬å·å¼€å¤´ä¸”åŒ…å«"æ•°å­—+äºº"ï¼Œå½“å‰è¡Œä¸åŒ…å«"æ•°å­—+äºº"æ¨¡å¼
                # ä¾‹å¦‚ï¼š(æ€æƒ³æ”¿æ²») 2 äºº
                if next_line and re.match(r'^\(', next_line) and re.search(r'\d+\s*äºº', next_line) and not re.search(r'\d+\s*äºº', line):
                    should_merge = True
                
                # æ¡ä»¶3ï¼šé™¢æ ¡è¡Œ + ä¸“ä¸šç»„è¡Œåˆå¹¶ï¼ˆä»…å½“é™¢æ ¡è¡Œæ²¡æœ‰äººæ•°æ—¶ï¼‰
                # å½“å‰è¡Œï¼š4ä½æ•°å­—å¼€å¤´ï¼Œæ— "äºº"ï¼ˆé™¢æ ¡ä»£ç +åç§°ï¼Œæ— äººæ•°ï¼‰
                # ä¸‹ä¸€è¡Œï¼š2-3ä½æ•°å­—å¼€å¤´ï¼Œæœ‰"äºº"ï¼ˆä¸“ä¸šç»„ä»£ç +äººæ•°ï¼‰
                # æ³¨æ„ï¼šå¦‚æœå½“å‰è¡Œå·²ç»æœ‰"äºº"ï¼Œè¯´æ˜æ˜¯å®Œæ•´çš„é™¢æ ¡ä¸“ä¸šç»„è¡Œï¼Œä¸åº”è¯¥åˆå¹¶
                current_is_school_no_count = re.match(r'^\d{4}\s+', line) and not re.search(r'\d+\s*äºº', line)
                next_is_group = re.match(r'^\d{2,3}\s+', next_line) and re.search(r'\d+\s*äºº', next_line)
                if current_is_school_no_count and next_is_group:
                    should_merge = True
                
                if should_merge:
                    merged_lines.append(line + ' ' + next_line)
                    i = next_idx + 1  # è·³è¿‡æ‰€æœ‰å·²å¤„ç†çš„è¡Œ
                    continue
            
            merged_lines.append(line)
            i += 1
        
        # === å¼€å§‹è§£æ ===
        current_row = 1
        headers_inserted = False
        last_was_title = False  # è·Ÿè¸ªä¸Šä¸€è¡Œæ˜¯å¦æ˜¯æ ‡é¢˜
        
        for line in merged_lines:
            line = line.strip()
            if not line:
                continue
            
            # è·³è¿‡æ ‡é¢˜è¡Œï¼ˆä»¥ # å¼€å¤´æˆ–åŒ…å«"æ‰¹æ¬¡"å…³é”®è¯ï¼‰
            if line.startswith('#'):
                # æ ‡é¢˜å•ç‹¬ä¸€è¡Œï¼Œä¸Šä¸‹åŠ ç©ºè¡Œ
                if current_row > 1:
                    current_row += 1  # ä¸Šæ–¹ç©ºè¡Œ
                clean_title = line.lstrip('#').strip()
                write_text_row(ws, current_row, clean_title, align_left)
                current_row += 1
                current_row += 1  # ä¸‹æ–¹ç©ºè¡Œ
                last_was_title = True
                continue
            
            # è·³è¿‡è¯´æ˜æ–‡å­—ï¼ˆè¶…é•¿æ®µè½ + ç‰¹å®šå…³é”®è¯ï¼‰
            if self.is_instruction_line(line):
                continue
            
            # é¢å¤–è¿‡æ»¤ï¼šåŒ…å«"é™¢æ ¡åç§°å‰"ã€"ä¸“ä¸šåç§°å‰"ç­‰è¯´æ˜æ€§å…³é”®è¯
            if any(kw in line for kw in ["é™¢æ ¡åç§°å‰", "ä¸“ä¸šåç§°å‰", "æ‹›ç”Ÿäººæ•°åæ‹¬å·å†…"]):
                continue
            
            # åªåœ¨ä»¥ä¸‹æƒ…å†µæ’å…¥è¡¨å¤´ï¼š
            # 1. ç¬¬ä¸€æ¬¡é‡åˆ°æ•°æ®ï¼ˆheaders_inserted=Falseï¼‰
            # 2. åˆšé‡åˆ°è¿‡æ ‡é¢˜ï¼ˆlast_was_title=Trueï¼‰
            if not headers_inserted or last_was_title:
                headers = ["ä¸“ä¸šç»„/ä¸“ä¸šä»£ç ", "ä¸“ä¸šç»„/ä¸“ä¸šæè¿°", "æ‹›ç”Ÿäººæ•°/å¤‡æ³¨"]
                for col, val in enumerate(headers, 1):
                    cell = ws.cell(row=current_row, column=col, value=val)
                    cell.fill = header_fill
                    cell.font = header_font
                    cell.alignment = align_center
                    cell.border = border
                current_row += 1
                headers_inserted = True
                last_was_title = False
            
            # åŒ¹é…æ ¼å¼: æ•°å­— + åç§° + Xäºº...
            # å…è®¸åç§°å’Œäººæ•°ä¹‹é—´æ²¡æœ‰ç©ºæ ¼ï¼ˆå¦‚ï¼šè¥¿ç­ç‰™è¯­1äººï¼‰
            match = re.match(r'^(\d{2,4})\s+(.+?)(\d+\s*äºº.*)$', line)
            
            if match:
                code = match.group(1)
                name = match.group(2).strip()
                remark = match.group(3).strip()
                
                write_data_row(ws, current_row, [code, name, remark], styles)
                current_row += 1
            else:
                # æ”¹è¿›çš„è·¨è¡Œåˆ¤æ–­ï¼š
                # æƒ…å†µ1ï¼šä»¥2-4ä½æ•°å­—å¼€å¤´ï¼ˆå¯èƒ½æ˜¯æ–°æ•°æ®è¡Œçš„ä»£ç ï¼‰ï¼Œåˆ™è§†ä¸ºç‹¬ç«‹æ•°æ®
                if re.match(r'^\d{2,4}\s+', line):
                    # è¿™çœ‹èµ·æ¥åƒæ˜¯ä¸€ä¸ªæ–°çš„æ•°æ®è¡Œï¼ˆæœ‰ä»£ç ï¼‰ï¼Œå°è¯•è§£æ
                    # æ ¼å¼å¯èƒ½æ˜¯ï¼š01 ä¸“ä¸šåç§°(ä¸­å¤–åˆä½œåŠå­¦)(ä¸­æ„åˆä½œåŠå­¦)
                    parts = re.match(r'^(\d{2,4})\s+(.+)$', line)
                    if parts:
                        code = parts.group(1)
                        name = parts.group(2).strip()
                        # æ²¡æœ‰äººæ•°ä¿¡æ¯ï¼Œå¤‡æ³¨ä¸ºç©º
                        write_data_row(ws, current_row, [code, name, ""], styles)
                        current_row += 1
                    else:
                        # è§£æå¤±è´¥ï¼Œè¿½åŠ åˆ°ä¸Šä¸€è¡Œ
                        if current_row > 2:
                            prev_remark = ws.cell(row=current_row-1, column=3).value or ""
                            ws.cell(row=current_row-1, column=3).value = prev_remark + ' ' + line
                
                # æƒ…å†µ2ï¼šåŒ…å«"Xäºº"æ¨¡å¼ï¼ˆå¯èƒ½æ˜¯è·¨é¡µæ•°æ®çš„å»¶ç»­éƒ¨åˆ†ï¼‰
                elif re.search(r'\d+\s*äºº', line):
                    # è¿™æ˜¯è·¨é¡µæ•°æ®ï¼ä¿ç•™ä¸ºç‹¬ç«‹è¡Œ
                    # ä»£ç ä¸ºç©ºï¼Œæ•´è¡Œä½œä¸ºåç§°+å¤‡æ³¨
                    # å°è¯•åˆ†ç¦»åç§°å’Œäººæ•°
                    parts = re.match(r'^(.+?)(\d+\s*äºº.*)$', line)
                    if parts:
                        name = parts.group(1).strip()
                        remark = parts.group(2).strip()
                        write_data_row(ws, current_row, ["", name, remark], styles)
                        current_row += 1
                    else:
                        # æ— æ³•åˆ†ç¦»ï¼Œæ•´è¡Œä½œä¸ºå¤‡æ³¨
                        write_data_row(ws, current_row, ["", "", line], styles)
                        current_row += 1
                
                # æƒ…å†µ3ï¼šæ™®é€šæ–‡æœ¬ï¼Œè¿½åŠ åˆ°ä¸Šä¸€è¡Œå¤‡æ³¨
                else:
                    if current_row > 2:
                        prev_remark = ws.cell(row=current_row-1, column=3).value or ""
                        ws.cell(row=current_row-1, column=3).value = prev_remark + ' ' + line
        
        autofit_columns(ws, 3)
        setup_columns(ws)
        return wb

    def parse_to_excel(self, text):
        wb = Workbook()
        ws = wb.active
        
        # 1. ä¼˜å…ˆå°è¯• HTML è¡¨æ ¼è§£æ
        soup = BeautifulSoup(text, 'html.parser')
        if soup.find('table'):
            print("   ğŸ“Š æ£€æµ‹åˆ° HTML è¡¨æ ¼ï¼Œæ‰§è¡Œç»“æ„åŒ–è§£æ...")
            _, max_cols = html_table_to_excel(soup, ws)
            autofit_columns(ws, max_cols)
            if max_cols == 3:
                setup_columns(ws)
            return wb

        # 2. æ£€æµ‹æ˜¯å¦æ˜¯ PaddleOCR çš„ç®€å•æ ¼å¼ï¼ˆæ¯è¡Œç‹¬ç«‹ï¼Œæ ¼å¼è§„æ•´ï¼‰
        lines = [l.strip() for l in text.split('\n') if l.strip()]
        paddle_format_count = sum(1 for l in lines if re.match(r'^\d{2,4}\s+.+\s+\d+\s*äºº', l))
        
        if paddle_format_count > len(lines) * 0.5:  # è¶…è¿‡50%çš„è¡Œç¬¦åˆæ ¼å¼
            print("   ğŸ“ æ£€æµ‹åˆ° PaddleOCR ç®€å•æ ¼å¼ï¼Œä½¿ç”¨è¡Œè§£æ...")
            return self._parse_paddle_format(text, wb, ws)

        # 3. æ–‡æœ¬æ¨¡å¼ï¼šä¸Šä¸‹æ–‡æ„ŸçŸ¥è§£æ (2-Pass Strategy)
        header_fill, header_font = get_header_style()
        styles = get_common_styles()
        align_center, align_left, border = styles

        # --- Pass 1: åˆ†ç±» ---
        raw_lines = text.split('\n')
        tagged_lines = []
        for line in raw_lines:
            l_type, l_content = self.classify_line(line)
            if l_type:
                tagged_lines.append({'type': l_type, 'content': l_content})

        # --- Pass 2: å¤„ç† (çŠ¶æ€æœº) ---
        current_row = 1
        headers_inserted = False
        last_data_row_idx = None # æŒ‡å‘ä¸Šä¸€æ¡æœ‰æ•ˆæ•°æ®(Groupæˆ–Major)ï¼Œç”¨äºè¿½åŠ å¤‡æ³¨

        # å¾…å†™å…¥çš„éç»“æ„åŒ–æ–‡æœ¬ç¼“å­˜
        pending_text_lines = [] 

        def flush_pending_text():
            nonlocal current_row
            if pending_text_lines:
                if current_row > 1: current_row += 1
                for txt in pending_text_lines:
                    write_text_row(ws, current_row, txt, align_left)
                    current_row += 1
                pending_text_lines.clear()

        for i, item in enumerate(tagged_lines):
            l_type = item['type']
            content = item['content']
            
            #ä»¥æ­¤å½“å‰è¡Œä¸ºä¸­å¿ƒï¼ŒæŸ¥çœ‹ä¸Šä¸‹æ–‡
            prev_type = tagged_lines[i-1]['type'] if i > 0 else None
            next_type = tagged_lines[i+1]['type'] if i < len(tagged_lines) - 1 else None
            
            # --- é€»è¾‘æ ¸å¿ƒï¼šå»å™ªä¸å½’å¹¶ ---

            # A. æ ‡é¢˜å¤„ç†
            if l_type == self.LINE_TYPE_TITLE:
                # ç‰¹æ®Šå»å™ªï¼šå¦‚æœå½“å‰æ˜¯"å¼±æ ‡é¢˜"(æ— #)ï¼Œä¸”ä¸‹ä¸€è¡Œä¹Ÿæ˜¯æ ‡é¢˜ï¼Œåˆ™è®¤ä¸ºå½“å‰è¡Œæ˜¯é¡µçœ‰/é‡å¤æ ‡é¢˜ -> ä¸¢å¼ƒ
                if not content.startswith('#') and next_type == self.LINE_TYPE_TITLE:
                    print(f"    ğŸ—‘ï¸ ä¸¢å¼ƒå†—ä½™æ ‡é¢˜: {content}")
                    continue
                
                flush_pending_text()
                # æ ‡é¢˜å‡ºç°ï¼Œé‡ç½®æ•°æ®ä¸Šä¸‹æ–‡ï¼ˆä¸èƒ½è·¨æ ‡é¢˜åˆå¹¶å¤‡æ³¨ï¼‰
                last_data_row_idx = None
                headers_inserted = False # æ–°æ®µè½å¯èƒ½éœ€è¦æ–°è¡¨å¤´
                
                if current_row > 1: current_row += 1
                write_text_row(ws, current_row, content, align_left)
                current_row += 1
                continue

            # B. è¯´æ˜æ–‡å­—å¤„ç†
            if l_type == self.LINE_TYPE_INSTRUCTION:
                # ç›´æ¥å¿½ç•¥
                continue

            # C. æœªçŸ¥è¡Œ (UNKNOWN) å¤„ç† - æœ€å…³é”®çš„éƒ¨åˆ†
            next_type = tagged_lines[i+1]['type'] if i < len(tagged_lines) - 1 else None

            if l_type == self.LINE_TYPE_UNKNOWN:
                # è§„åˆ™1a: ç´§è·Ÿåœ¨æ ‡é¢˜å‰é¢çš„ UNKNOWN -> è§†ä¸ºé¡µçœ‰/é¡µè„šå™ªéŸ³ (å¦‚ "Â·ç‰©ç†ç§‘ç›®...") -> ä¸¢å¼ƒ
                if next_type == self.LINE_TYPE_TITLE:
                    print(f"    ğŸ—‘ï¸ ä¸¢å¼ƒæ ‡é¢˜å‰å™ªéŸ³: {content}")
                    continue

                # è§„åˆ™1b: ç´§è·Ÿåœ¨æ ‡é¢˜åé¢çš„ UNKNOWN -> è§†ä¸ºè¡¨å¤´å™ªéŸ³ (å¦‚ "åä¸“ä¸š...") -> ä¸¢å¼ƒ
                if prev_type == self.LINE_TYPE_TITLE:
                    print(f"    ğŸ—‘ï¸ ä¸¢å¼ƒæ ‡é¢˜åå™ªéŸ³: {content}")
                    continue
                
                # è§„åˆ™2: å¦‚æœå‰é¢æœ‰æ•°æ®è¡Œ -> è§†ä¸ºå¤‡æ³¨ -> åˆå¹¶
                if last_data_row_idx:
                    current_val = ws.cell(row=last_data_row_idx, column=3).value or ""
                    # é˜²æ­¢æ— é™è¿½åŠ çš„å®‰å…¨é™åˆ¶
                    if len(current_val) < 800:
                        ws.cell(row=last_data_row_idx, column=3).value = f"{current_val}{content}"
                    continue
                
                # è§„åˆ™3: æ—¢ä¸åœ¨æ ‡é¢˜åï¼Œä¹Ÿæ²¡æ•°æ®å¯ä¾é™„ -> è§†ä¸ºæ­£æ–‡/æ®µè½æ–‡å­— -> ç¼“å­˜å¾…å†™
                pending_text_lines.append(content)
                continue

            # D. æ•°æ®è¡Œ (GROUP / MAJOR) å¤„ç†
            # åªè¦æ˜¯æ•°æ®è¡Œï¼Œå°±è¦å…ˆæŠŠä¹‹å‰ç¼“å­˜çš„"ç¢æ–‡å­—"å†™å‡ºå»(å¦‚æœæœ‰çš„è¯)
            if l_type in [self.LINE_TYPE_GROUP, self.LINE_TYPE_MAJOR]:
                flush_pending_text()
                
                # ç¡®ä¿è¡¨å¤´å­˜åœ¨
                if not headers_inserted:
                    if current_row > 1: current_row += 1
                    self._insert_headers(ws, current_row, header_fill, header_font, align_center, border)
                    current_row += 1
                    headers_inserted = True

                # å®šä¹‰ä¸€ä¸ªå†…éƒ¨å‡½æ•°å¿«é€Ÿå†™å…¥
                def process_and_write(code, name, raw_text):
                    nonlocal current_row, last_data_row_idx
                    # ä½¿ç”¨æ–°çš„æµå¼è§£æå™¨
                    entries = self.parse_detailed_line(code, name, raw_text)
                    for e_code, e_name, e_remark in entries:
                        print(f"DEBUG_WRITE: Code='{e_code}', Name='{e_name}'")
                        write_data_row(ws, current_row, [e_code, e_name, e_remark], styles)
                        last_data_row_idx = current_row
                        current_row += 1

                # è‹¥æ˜¯ GROUP
                if l_type == self.LINE_TYPE_GROUP:
                    for match in self.GROUP_PATTERN.finditer(content):
                        name = match.group(2)
                        name = re.sub(r'(\D)(\d+)', r'\1 \2', name) 
                        process_and_write(match.group(1), name, match.group(3))
                
                # è‹¥æ˜¯ MAJOR
                elif l_type == self.LINE_TYPE_MAJOR:
                    for match in self.MAJOR_PATTERN.finditer(content):
                        process_and_write(match.group(1), match.group(2), match.group(3))

        flush_pending_text()
        autofit_columns(ws, 3)
        setup_columns(ws)
        return wb

    def parse_detailed_line(self, first_code, first_name, first_remark_start_text):
        """
        åŸºäºæ‹¬å·æ·±åº¦çš„æµå¼è§£æ (Bracket-Aware Stream Parsing)ã€‚
        ä» first_remark_start_text å¼€å§‹æ‰«æï¼Œæå–å½“å‰æ¡ç›®çš„å¤‡æ³¨ï¼Œå¹¶æ£€æµ‹æ˜¯å¦æœ‰åç»­æ¡ç›®ã€‚
        
        Args:
            first_code: ç¬¬ä¸€ä¸ªæ¡ç›®çš„ä»£ç 
            first_name: ç¬¬ä¸€ä¸ªæ¡ç›®çš„åç§°
            first_remark_start_text: ç¬¬ä¸€ä¸ªæ¡ç›®"äºº"å­—ä¹‹åçš„æ‰€æœ‰æ–‡æœ¬ï¼ˆåŒ…æ‹¬"äºº"å­—æœ¬èº«å¦‚æœä¹‹å‰æ²¡åˆ‡åˆ†å¹²å‡€çš„è¯ï¼Œä½†æ ¹æ®æ­£åˆ™é€»è¾‘ï¼Œè¿™é‡Œä¼ å…¥çš„åº”è¯¥æ˜¯ \d+äºº... è¿™ä¸€æ®µï¼‰
        
        Returns:
            [(code, name, remark), ...]
        """
        results = []
        
        # æ„é€ å®Œæ•´çš„å¾…æ‰«æå­—ç¬¦ä¸²ï¼šä¸ºäº†ç»Ÿä¸€é€»è¾‘ï¼Œæˆ‘ä»¬å°†ç¬¬ä¸€ä¸ªæ¡ç›®çš„ "Xäºº..." ä½œä¸ºæµçš„èµ·ç‚¹
        # ä½†è¦æ³¨æ„ï¼Œè°ƒç”¨æ–¹ä¼ å…¥çš„ first_remark_start_text å®é™…ä¸Šå°±æ˜¯ "matched_group_3"ï¼Œå³ "\d+äºº..."
        
        # åˆå§‹çŠ¶æ€
        current_code = first_code
        current_name = first_name
        
        # å¾…æ‰«æçš„æ–‡æœ¬æµ
        stream = first_remark_start_text
        
        cursor = 0
        length = len(stream)
        bracket_depth = 0
        
        # å½“å‰æ¡ç›®çš„å¤‡æ³¨ buffer
        current_remark_buffer = []
        
        while cursor < length:
            char = stream[cursor]
            
            # --- 1. æ‹¬å·æ·±åº¦ç»´æŠ¤ ---
            if char in 'ï¼ˆ(':
                bracket_depth += 1
                # print(f"DEBUG: Char '{char}' at {cursor}. Depth UP -> {bracket_depth}")
            elif char in 'ï¼‰)':
                if bracket_depth > 0:
                    bracket_depth -= 1
                # print(f"DEBUG: Char '{char}' at {cursor}. Depth DOWN -> {bracket_depth}")
            
            # --- 2. æ–°æ¡ç›®æ£€æµ‹ (ä»…å½“ä¸åœ¨æ‹¬å·å†…æ—¶) ---
            if bracket_depth == 0:
                remaining = stream[cursor:]
                
                # æ­£åˆ™é¢„è¯» (Lookahead): 
                new_entry_pattern = re.compile(r"^\s*([A-Za-z0-9]{2})?\s*([\u4e00-\u9fa5]{2,}[^\säºº]*)\s*(?=\d+\s*äºº)")
                
                match = new_entry_pattern.match(remaining)
                if match:
                    print(f"    âœ‚ï¸  Split Entry Found at char '{char}': Code='{match.group(1)}', Name='{match.group(2)}'")
                    # æ‰¾åˆ°äº†æ–°æ¡ç›®ï¼
                    # ä¿å­˜å½“å‰æ¡ç›®
                    results.append((current_code, current_name, "".join(current_remark_buffer).strip()))
                    
                    # æ›´æ–°çŠ¶æ€
                    current_code = match.group(1)
                    current_name = match.group(2)
                    current_remark_buffer = [] # æ¸…ç©º buffer
                    
                    # ç§»åŠ¨æ¸¸æ ‡ï¼šè·³è¿‡ä»£ç å’Œåå­—ï¼Œç›´æ¥æŒ‡ä¸‹ä¸€æ¡ç›®çš„ "äººæ•°" èµ·å§‹å¤„ (å› ä¸º new_entry_pattern æ²¡æœ‰æ¶ˆè€—äººæ•°)
                    # match.end() æ˜¯åŒ¹é…åˆ°çš„ Code+Name çš„ç»“æŸä½ç½®
                    cursor += match.end()
                    continue
            
            # --- 3. æ™®é€šå­—ç¬¦å¤„ç† ---
            current_remark_buffer.append(char)
            cursor += 1
            
        # å¾ªç¯ç»“æŸï¼Œä¿å­˜æœ€åä¸€ä¸ªæ¡ç›®
        results.append((current_code, current_name, "".join(current_remark_buffer).strip()))
        
        return results

    def _insert_headers(self, ws, row, fill, font, align, border):
        headers = ["ä¸“ä¸šç»„/ä¸“ä¸šä»£ç ", "ä¸“ä¸šç»„/ä¸“ä¸šæè¿°", "æ‹›ç”Ÿäººæ•°/å¤‡æ³¨"]
        for col, val in enumerate(headers, 1):
            cell = ws.cell(row=row, column=col, value=val)
            cell.fill = fill
            cell.font = font
            cell.alignment = align
            cell.border = border

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å®‰å¾½çœæ‹›ç”Ÿè®¡åˆ’è§£æå™¨")
    parser.add_argument("image_path", nargs='?', default=None, help="å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--output-dir", default="output/anhui", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--md-input", help="ç›´æ¥è§£æå·²æœ‰çš„ Markdown æ–‡ä»¶")
    parser.add_argument("--province", help="çœä»½ä»£ç ï¼ˆå…¼å®¹æ€§å‚æ•°ï¼‰")
    parser.add_argument("--model", choices=['auto', 'ocr', 'v3'], default='auto',
                        help="OCR æ¨¡å‹é€‰æ‹©: auto=è‡ªåŠ¨æ£€æµ‹, ocr=å¼ºåˆ¶PaddleOCR, v3=å¼ºåˆ¶StructureV3")
    args = parser.parse_args()

    os.makedirs(args.output_dir, exist_ok=True)
    processor = AnhuiProcessor()
    
    # è®¾ç½®æ¨¡å‹åå¥½
    processor.model_preference = args.model
    
    if args.md_input:
        print(f"ğŸ“„ æ­£åœ¨ä»æœ¬åœ° Markdown éªŒè¯è§£æ: {args.md_input}")
        with open(args.md_input, 'r', encoding='utf-8') as f:
            md_text = f.read()
        
        base_name = Path(args.md_input).stem
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        wb = processor.parse_to_excel(md_text)
        excel_path = Path(args.output_dir) / f"{base_name}_v3_{timestamp}.xlsx"
        wb.save(excel_path)
        print(f"   âœ“ Excel å·²ç”Ÿæˆ (æœ¬åœ°éªŒè¯): {excel_path}")
    elif args.image_path:
        processor.run(args.image_path, args.output_dir)
    else:
        print("âŒ è¯·æä¾›å›¾ç‰‡è·¯å¾„æˆ– --md-input è·¯å¾„")
